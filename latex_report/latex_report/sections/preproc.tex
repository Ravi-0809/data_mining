\section{Pre-processing}
Data preprocessing techniques are applied to the dataset to clean up redundant data and make the dataset more suitable for visualizations and data mining tasks. Three data preprocessing techniques are applied to the dataset and are detailed below. 

\subsection{Data cleaning}
The original dataset and the dataset obtained after merging are both very sparse in nature. They contained lots of zero values and missing values. The first task in data cleaning is to handle the missing values in the dataset. To handle this problem, all the missing values are filled with zeros. This works well for the dataset because if a value is missing in the census data, it directly implies that no person belonging to that demographic exists in that college. As all the non-zero values total to the total students enrolled, replacing missing census data with zeros is an appropriate technique for this dataset. For some cases, the entries(rows) containing zero "total students", or a null value in place of college name, degree name, etc are removed entirely as these rows cannot contribute to any mining techniques or visualizations.
Another task in data cleaning is to reduce the number of unique values in categorical columns by removing its case sensitivity. For example, "commerce" and "COMMERCE" were counted as two different disciplines in the dataset. This problem existed across majority of the categorical columns and is fixed throughout the dataset.

\subsection{Data Reduction}
As part of data reduction, features which are redundant or do not add any value to visualization or data mining tasks are identified and removed. These features comprise of various "id" and "remarks" fields and other manually identified fields including redundant data like "faculty name", "survey year", etc. 

\subsection{Data Transformation}
Two different data transformation techniques are applied on the dataset namely - Normalization and Discretization. 
For normalization, min-max normalization technique is used to normalize the census or demographic of students in each entry (for each degree in each college). For the given dataset, the min value is 0 and the max value is the total number of students enrolled in that degree in that college. As a result of min-max normalization, we get a fraction or percentage of each type of person in the college and as a result we can compare the numbers across different rows. 
Discretization is done on the categorical features of this dataset as well as the census part of the dataset. For the classification task, binarization is done on the categorical features. This technique is chosen over one-hot encoding because one-hot encoding further increases the dimensionality of the dataset. And since the dataset is already highly dimensional, either binarization or Ordinal encoding are better suited to the task. 
For the association rule mining, the census data is discretized by using equal interval binning. The bin widths are chosen manually by trial and error and optimized for performance and results. This binning is necessary because we need to convert the census data into a transaction type database which is required for association rule mining. Binning gives us better results than considering a person to be "present in the transaction database" by exceeding a threshold.
